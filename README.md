# AIGameTranslater
Сделано мной совместно с Чатом ГПТ. ОЧЕНЬ РАННЯЯ ВЕРСИЯ, СКОРЕЕ ДАЖЕ НАРАБОТКА ДЛЯ ПРИКОЛА
- Немного истории: Мне просто надоело напрягать мозги или сидеть с переводчиком и переводить азиатские гача игры и визуальные новелы, поэтому я напечатал эту прогу (не совсем я, но руку точно приложил в некоторых местах)
## ОПИСАНИЕ (желательно всё прочитать, даже мою болтовню)
Локальный AI переводчик использующий ресурсы ПК для перевода игр и другово рода контента. Работает по принципу: Раз в 1-2 секунды (можно настроить) делает скриншот области -> отправляет скриншот нейросети -> нейросеть распознает текст и переводит на русский -> выводит текст на экран (Profit)
## МИНИМАЛЬНЫЕ СИСТЕМНЫЕ ТРЕБОВАНИЯ (что бы хоть что-то показало/перевело):
Если модель Qwen3-VL-8B-Instruct Q4_K_M (vision, с mmproj)
- GPU: RTX с 8 ГБ VRAM. (RTX 2060 SUPER)
- ОЗУ: 24–32 ГБ .
- CPU: любой 6–8 ядер.
- Диск: модель + mmproj ≈ 6–8 ГБ суммарно.

Если модель Qwen3-VL-4B-Instruct Q4_K_M (vision, с mmproj)
- GPU: RTX с 6–8 ГБ VRAM. (RTX 2060)
- ОЗУ: 16 ГБ (с запасом лучше 24).
- CPU: любой 4–6 ядер.
- Диск: модель + mmproj ≈ 3–5 ГБ суммарно.

А вы что думали, будет все радужно? Можно еще хуже (легче) модель поставить, но качество перевода оставит желать лучшего.
Конечно есть аналоги более щадящие по железу (хотя с легкими моделями будет примерно тоже самое), я и сам изначально пробовал его сделать, но мне абсолютно не понравилось как оно переводит и как работает впринципе. Почти всегда текст похожий на "Она - со мной, углепластик...", ну вы поняли. Распознавание текста тоже хромает так еще и на GPU завести проблематично, а на CPU я видел нагрузку 102%... Поэтому вариант с AI меня более чем устраивает. 
Моё железо:
- I7 12700KF
- 32 ГБ ОЗУ
- RTX 4070 Ti Super
- На модели Qwen3-VL-8B-Instruct Q4_K_M нагрузка следующая: CPU - 5%, GPU - +-50% и нагрузка на VRAM 14GB и температура не растет выше 60 градусов, ОЗУ - 500мб так как видеопамяти хватает. Если вас такое устраивает или вы просто любопытный и хотите попробовать, то перейдем к следующему этапу.

### ПОДГОТОВКА
1) Зайдите на [HuggingFace](https://huggingface.co/) или другой сайт с моделями
2) Скачайте VL (vision, с mmproj) модель формата .GUFF и модель mmproj тоже формата .GUFF (она должна идти в "комплекте" с моделью, если нет ищите другую, ОБЯЗАТЕЛЬНО что бы mmproj был от той же модели, которую вы качаете)
3) Как скачаете переходите к установке

### УСТАНОВКА
1) Скачать
2) Распаковать в удобное место (желательно на SSD и в папку без русских символов)
3) Закинуть модели по пути "GameTranslator\_internal\models\llm"
<img width="855" height="331" alt="image" src="https://github.com/user-attachments/assets/b82ca01e-8698-4812-a316-e19745601961" />

4) Запустить

### НАСТРОЙКА
#### 1) При запуске появится огромное окно с настройками (оно необходимо для более тонкой настройки для каждой конфигурации ПК) и область, которая будет переводить и выводить перевод, область можно перемещать, увеличивать, уменьшать, разделять, добавлять.
<img width="980" height="1385" alt="image" src="https://github.com/user-attachments/assets/f97307d4-bae1-4d42-8cf7-e530d2528fd1" />

#### 2) Кнопка "Начать перевод" запускает сервер с AI и начинает захватывать и переводить текст под областью
#### 3) Окно для захвата
- выберите процесс игры или необходимой программы
#### 4) Модели 
- Если вы правильно установили модели, то они сами подхватятся в программе. (если нет проверяйте путь, возможно неправильно поставили)
#### 5) Лор файл
- небольшой сборник терминов для нейросети, что бы она правильно переводила имена (определяла их пол, если персонаж женщина, а так же подстраивала перевод под нее), термины, фракции, организации и т.д. Можете сделать сами или с помощью той же онлайн нейросети попросить создать его (напишите примерно: Дай краткое описание всех персонажей (пол и т.д), терминов, фракций, организаций и т.д игры "название игры", а так же перевод всего этого с английского на русский (или другой интересующий вас язык, перевод с поднебесной и других языков поддерживается). Если лора нет, оставьте пустым (перевод может ухудшиться). По умолчанию находится в "GameTranslator/_internal/assets"
#### 6) Смена шрифта, его размера и толщина
- тут всё просто (не спрашивайте почему там "гарнитура" я сам не знаю), там все шрифты в вашей системе, выбирайте любой и подгоняйте размер как вам нужно.
### ВСЕ ЧТО ИДЕТ ДАЛЬШЕ ВЛИЯЕТ НА ВАШУ ПРОИЗВОДИТЕЛЬНОСТЬ И РАБОТУ ИИ В ЦЕЛОМ, В КОНЦЕ Я ДАМ НЕБОЛЬШУЮ СВОДКУ, ЧТО ЗА ЧТО ОТВЕЧАЕТ КАКОЕ ВЛИЯНИЕ НА ПРОИЗВОДИТЕЛЬНОСТЬ И РАБОТУ ИИ
#### 7) Настройка модели
- максимум токенов = максимальный размер ответа AI
- timeout - максимальное время овета AI, если не справился сбрасывает ответ и по новой думает (если словил жесткий затуп может помочь)
- temperature - "креативность" AI
- top_p - та же "креативность", но в другом плане.
#### 8) Доп. параметры генерации
- top_k - еще одна "креативность" (да, ее нужно много, что бы ограничивать или наоборот дать простор в переводе)
- repeat_penalty - БОЛЬШЕ КРЕАТИВНОСТИ
- seed - не смешно уже, опять креативность
- slot_id - место для вашего лора и промпта, по умолчанию 0, пусть и отсается 0.
- cache_promt - загружается ли промпт+лор в память. Пусть всегда включено, если не используете иначе
#### 9) Сервер llama
- ctx-size - Сколько токенов уместится в запросе+истории
- batch-size - размер партии токенов на шаге. Влияет на пропускную способность и немного на VRAM
- ubatch-size - подпартия, главный «жир» по VRAM
- parralel - параллельные запросы к серверу. Для нескольких областей может ускорять, но VRAM растёт почти линейно.
- ngl - ниже = меньше жор GPU. Выше = больше жор на GPU. Всё просто. можете оставить 999 и проверить как работает (будет брать столько, сколько ему надо, не больше).
- host - не трогайте, если не знаете как
- port - то же самое
#### 10) Константы
- FPS захвата - больше = чаще происходит скрин на отправку, меньше = реже. По умолчанию 1 = 1 скрин в секунду. Меняйте по своему усмотрению
- MIN_THUMB_DELTA - Чувствительность «изменился ли кадр» (по thumbnail). выше значение = меньше ложных переводов, но позже реагирует.
- Плавный вывод - если включен = режим новеллы, текст появляется плавно (скорость меняется стрелочками вверх или вних), если выключен = появляется сразу по мере поступления текста
- Размер ручек рамки - пока не работает, позволяет менять размер уголков для растягивания области. (Ниже будет так же размер рамок)
#### 11) Настроить промпт
- позволяет в ручную настраивать промпт для нейросети.
#### 12) Предпросмотр промпта
- показывает текущий промпт. Мной уже загружен промпт, можете использовать его как шаблон для своего.
### ГЛАВНОЕ ЕСЛИ ВЫ МЕНЯЕТЕ ПРОМПТ И ИСПОЛЬЗУЕТЕ ФАЙЛ ЛОРА ТО В КОНЦЕ ЯБАЗАТЕЛЬНО СДЕЛАЙТЕ ТАК, ИНАЧЕ ЛОР НЕ СРАБОТАЕТ:
- === LORE START ===
{{LORE}}
=== LORE END ===
<img width="753" height="583" alt="image" src="https://github.com/user-attachments/assets/3b74a6ba-79b5-4c19-8a1f-7e4f1570247d" />

#### 14) Настройка самой области
- Потяните за любой уголок что бы растянуть/стянуть область.
- Потяните за рамку, что бы перенести область
- CTRL+ALT+N - создать новую область
- CTRL+ALT+D - разделить область на две отдельные, область захвата (оранжевая) и область перевода (синяя). И так же что бы соединить обратно
- TAB - сменить редактирование между захватом и переводом
- Delete (перед этим нажнмите на нужную область) - удалить область
- CTRL+ALT+F1 - полностю скрыть область
- CRTL+ALT+F2 - скрыть только рамки (оставить размытый фон)
- CTRL+ALT+Q - выход в настройки

Пока что это все настройки что есть, возможно что-то добавится, а что-то уберется.


После всех настроек и изменений области под себя, жмите кнопку "Начать перевод", через некоторое время, если все сделали правильно, появится перевод текста.
### ПОМНИТЕ, ЧТО ЭТО Я ВСЁ ДЕЛАЛ ДЛЯ СЕБЯ И ПРОСТО РЕШИЛ ПОДЕЛИТЬСЯ СО ВСЕМИ, ТАК ЧТО ВОЗМОЖНЫ ОШИБКИ. ТАК ЧТО ПИШИТЕ О БАГАХ, НЕДОРАБОТКАХ, БУДУ ИСПРАВЛЯТЬ ПО ВОЗМОЖНОСТИ. ЕСЛИ ВЫ ЗНАЕТ КАК МОЖНО ДОРАБОТАТЬ ТОТ ИЛИ ИНОЙ АСПЕКТ ПРОГРАММЫ БУДУ ПРИЗНАТЕЛЕН.

### ИЗВЕСТНЫЕ ОШИБКИ:
1) Самая главная ошибка в том, что оно существует
2) Текст бывает "обновляется", то есть постоянно начинает печататься заново в режиме плавного появления. Это из-за того, что нейросеть пытается выдать один и тот же текст по разному (где-то слово другое использует, где-то знаки меняет и т.д), можете попрбовать убавить ее кративность, но тогда возможно пострадает перевод.
3) Дурацкая рамка хватается не с первого раза

### ЧТО ХОЧУ СДЕЛАТЬ:
1) Возможность подключать две модели (Одна будет распазновать, другая переводить). В теории это может уменьшить нагрузку, так как будут использоваться специализированные модели, а не простые языковые
2) Возиожность сменить сервер. Сейчас используется llama, для меня это самое простое решение и в ней есть модели "все в одном"
3) Больше настроек для комфорта (настройки рамок, более приятный интрефейс и т.д)

### КАК И ОБЕЩАЛ БОЛЕЕ ДЕТАЛЬНОЕ ОПИСАНИЕ ДЛЯ НАСТРОЕК И ПРИМЕРНЫЕ ПРЕСЕТЫ ДЛЯ ОБЫЧНОГО ПК:

1) Модель
- Переводчик (VL-модель). Больше параметров → лучше качество/медленнее/тяжелее.
- Средне: Qwen3-VL-8B Q4_K_M (баланс), если тесно по VRAM — 3–4B Q4_K_M.
- mmproj (…mmproj-*.gguf) - визуальная «голова» для картинок. Обязателен для vision. Влияние на VRAM/скорость небольшое.

2) ctx-size (контекст)
- Сколько токенов уместится в запросе+истории. ↑ctx = ↑VRAM/KV-кеш, стабильнее длинные сцены.
- Средне: 6144–8192 (8 GB VRAM) / 8192–12288 (12–16 GB).

3) ngl (GPU-layers, «999» = максимум)
- Сколько слоёв модели держать на GPU. ↑ngl = ↑VRAM, но сильно быстрее. При OOM снижать.
- Средне: 999 (пусть сам возьмёт максимум). Если не лезет — 50–90.

4) batch-size
- Размер партии токенов на шаге. Влияет на пропускную способность и немного на VRAM.
- Средне: 128–256 (8 GB) / 256–384 (12–16 GB).

5) ubatch-size
- Подпартия, главный «жир» по VRAM. Первый рычаг при OOM/фризах.
- Средне: 24–48 (8 GB) / 64–96 (12–16 GB).

6) parallel
- Параллельные запросы к серверу. Для нескольких областей может ускорять, но VRAM растёт почти линейно.
- Средне: 1. Если 2 — урезать ubatch.

7) max_tokens (лимит ответа)
- Только на ответ, не на вход. ↑значение = дольше, чуть ↑память.
- Средне: 350–500.

8) temperature
- Стохастичность. Для перевода держи низко (стабильность терминов).
- Средне: 0.15–0.25.

9) top_p
- Nucleus-сэмплинг. Чем ниже — тем консервативнее.
- Средне: 0.9–0.95.

10) top_k
- Сэмплинг по top-k токенам. Для перевода чаще 0 (выкл.).

11) repeat_penalty
- Штраф за повторы. Слегка ↑ для борьбы с заиканием.
- Средне: 1.02–1.08.

12) seed
- 0 = псевдослучайность каждый раз. Фиксируй (>0) для воспроизводимости.
- Средне: 0 (если не нужно «один-в-один»).

13) timeout
- HTTP-таймаут запроса к серверу (сек).
- Средне: 12–18 s (под длину кадров/контекст).

14) FPS захвата
- Частота отправки кадров. ↑FPS = больше нагрузка, ↓латентность.
- Средне: 0.8–1.2.

15) MIN_THUMB_DELTA
- Чувствительность «изменился ли кадр» (по thumbnail). ↑значение = меньше ложных переводов, но позже реагирует.
- Средне: 0.02 (спокойные сцены 0.015; если «рябь» — 0.025–0.03).

16) Режим вывода: instant / smooth
- instant — моментально
- smooth — печать по символам (имитация новел и гач).

17) max_ctx_chars (для лора)(пока отсутствует)
- Сколько символов лора режем в system, чтобы не переполнять контекст.(сейчас стоит 30к в коде, под лор в 6-9к символов хватает)

### БЫСТРЫЕ ПРЕСЕТЫ:
8 GB VRAM - ctx=6144, batch=128, ubatch=32, parallel=1, ngl=999; max_tokens=400, temp=0.2, top_p=0.95, top_k=0, rep_pen=1.05, timeout=12, cache_prompt=ON; FPS=1.0, MIN_THUMB_DELTA=0.02, вывод instant.

12–16 GB VRAM - ctx=8192–12288, batch=256–384, ubatch=64–96, остальное как выше; timeout=15.

### Что крутить при проблемах:
1) OOM/500 (ошибка в консоле)/фризы: снижать ubatch → batch → ctx (в таком порядке)
2) Медленно отвечает: снизить ctx или max_tokens, поднять batch (если есть VRAM)
3) Перевод «гуляет»: temperature вниз (до 0.15), top_k=0, repeat_penalty≈1.05, включить seed>0 (если нужна стабильность).
4) Слишком часто перезапускает вывод: повысить MIN_THUMB_DELTA или увеличить порог «Δ-символов для форс-обновления»(пока выключено).

### Фууух, ну вроде все расписал, если что-то не понятно, нашли баг, есть предложение, создавайте issue, отвечу, прислушаюсь.
